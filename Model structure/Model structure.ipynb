{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure v1 (deprecate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11916,
     "status": "ok",
     "timestamp": 1711032044091,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "a_MZCpkCjFS9",
    "outputId": "98feb81a-3835-41b1-fc0e-0711292bb2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1711032045003,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "NN_BYkTvj7QA",
    "outputId": "9793a006-ebed-437d-f5ab-38c4fc48f02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/Thesis/Model\n"
     ]
    }
   ],
   "source": [
    "cd '/content/drive/MyDrive/Colab Notebooks/Thesis/Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7059,
     "status": "ok",
     "timestamp": 1710811707843,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "nmDGbx1zicXK",
    "outputId": "63b77019-b961-45ba-8f03-8afa82bbe3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name                Type           Output Shape  Trainable  \\\n",
      "0            input_9          InputLayer  [(None, 224, 224, 3)]       True   \n",
      "1        rescaling_4           Rescaling    (None, 224, 224, 3)       True   \n",
      "2    normalization_2       Normalization    (None, 224, 224, 3)       True   \n",
      "3        rescaling_5           Rescaling    (None, 224, 224, 3)       True   \n",
      "4      stem_conv_pad       ZeroPadding2D    (None, 225, 225, 3)       True   \n",
      "..               ...                 ...                    ...        ...   \n",
      "470     block7b_drop             Dropout      (None, 7, 7, 448)       True   \n",
      "471      block7b_add                 Add      (None, 7, 7, 448)       True   \n",
      "472         top_conv              Conv2D     (None, 7, 7, 1792)       True   \n",
      "473           top_bn  BatchNormalization     (None, 7, 7, 1792)       True   \n",
      "474   top_activation          Activation     (None, 7, 7, 1792)       True   \n",
      "\n",
      "     Number of Parameters Activation Function Kernel Size           Padding  \\\n",
      "0                       0                None        None              None   \n",
      "1                       0                None        None              None   \n",
      "2                       7                None        None              None   \n",
      "3                       0                None        None              None   \n",
      "4                       0                None        None  ((0, 1), (0, 1))   \n",
      "..                    ...                 ...         ...               ...   \n",
      "470                     0                None        None              None   \n",
      "471                     0                None        None              None   \n",
      "472                802816              linear      (1, 1)              same   \n",
      "473                  7168                None        None              None   \n",
      "474                     0               swish        None              None   \n",
      "\n",
      "    Strides Pooling Size  Dropout Rate  Normalization Momentum  \\\n",
      "0      None         None           NaN                     NaN   \n",
      "1      None         None           NaN                     NaN   \n",
      "2      None         None           NaN                     NaN   \n",
      "3      None         None           NaN                     NaN   \n",
      "4      None         None           NaN                     NaN   \n",
      "..      ...          ...           ...                     ...   \n",
      "470    None         None       0.19375                     NaN   \n",
      "471    None         None           NaN                     NaN   \n",
      "472  (1, 1)         None           NaN                     NaN   \n",
      "473    None         None           NaN                    0.99   \n",
      "474    None         None           NaN                     NaN   \n",
      "\n",
      "    Normalization Axis Reshape Target Shape  \n",
      "0                 None                 None  \n",
      "1                 None                 None  \n",
      "2                 None                 None  \n",
      "3                 None                 None  \n",
      "4                 None                 None  \n",
      "..                 ...                  ...  \n",
      "470               None                 None  \n",
      "471               None                 None  \n",
      "472               None                 None  \n",
      "473                [3]                 None  \n",
      "474               None                 None  \n",
      "\n",
      "[475 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the ResNet50 model without the top classification layer\n",
    "model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'Model': model.name,\n",
    "            'Layer Name': layer.name,\n",
    "            'Layer Type': type(layer).__name__,\n",
    "            'Output Shape': layer.output_shape,\n",
    "            'Trainable': layer.trainable,\n",
    "            'Number of Parameters': layer.count_params(),\n",
    "            'Activation Function': None,\n",
    "            'Kernel Size': None,\n",
    "            'Padding': None,\n",
    "            'Strides': None,\n",
    "            'Pooling Size': None,\n",
    "            'Dropout Rate': None,\n",
    "            'Normalization Momentum': None,\n",
    "            'Normalization Axis': None,\n",
    "            'Reshape Target Shape': None,\n",
    "            'Multiply': False,\n",
    "            'Add': False,\n",
    "\n",
    "        }\n",
    "\n",
    "        if hasattr(layer, 'activation'):\n",
    "            layer_dict['Activation Function'] = layer.activation.__name__\n",
    "        if hasattr(layer, 'kernel_size'):\n",
    "            layer_dict['Kernel Size'] = layer.kernel_size\n",
    "        if hasattr(layer, 'padding'):\n",
    "            layer_dict['Padding'] = layer.padding\n",
    "        if hasattr(layer, 'strides'):\n",
    "            layer_dict['Strides'] = layer.strides\n",
    "        if hasattr(layer, 'pool_size'):\n",
    "            layer_dict['Pooling Size'] = layer.pool_size\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_dict['Dropout Rate'] = layer.rate\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer_dict['Normalization Momentum'] = layer.momentum\n",
    "            layer_dict['Normalization Axis'] = layer.axis\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "            layer_dict['Reshape Target Shape'] = layer.target_shape\n",
    "        if layer.__class__.__name__ == 'Multiply':\n",
    "            layer_dict['Multiply'] = True\n",
    "        if layer.__class__.__name__ == 'Add':\n",
    "            layer_dict['Add'] = True\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# Extract layer information\n",
    "layer_info = extract_layer_info(model)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(layer_info)\n",
    "\n",
    "# Export DataFrame to a file (e.g., CSV)\n",
    "df.to_csv('efficientnetb4_structure.csv', index=False)\n",
    "\n",
    "# Display DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 17888,
     "status": "ok",
     "timestamp": 1711032454481,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "fPSal9s9kSS-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the ResNet50 model without the top classification layer\n",
    "models = [EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380,380,3)),\n",
    "         ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         DenseNet169(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)),]\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    \n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'Model': model.name,\n",
    "            'Layer Name': layer.name,\n",
    "            'Layer Type': type(layer).__name__,\n",
    "            'Output Shape': layer.output_shape,\n",
    "            'Trainable': layer.trainable,\n",
    "            'Number of Parameters': layer.count_params(),\n",
    "            'Activation Function': None,\n",
    "            'Kernel Size': None,\n",
    "            'Padding': None,\n",
    "            'Strides': None,\n",
    "            'Pooling Size': None,\n",
    "            'Dropout Rate': None,\n",
    "            'Normalization Momentum': None,\n",
    "            'Normalization Axis': None,\n",
    "            'Reshape Target Shape': None,\n",
    "            'Multiply': False,\n",
    "            'Add': False,\n",
    "\n",
    "        }\n",
    "\n",
    "        if hasattr(layer, 'activation'):\n",
    "            layer_dict['Activation Function'] = layer.activation.__name__\n",
    "        if hasattr(layer, 'kernel_size'):\n",
    "            layer_dict['Kernel Size'] = layer.kernel_size\n",
    "        if hasattr(layer, 'padding'):\n",
    "            layer_dict['Padding'] = layer.padding\n",
    "        if hasattr(layer, 'strides'):\n",
    "            layer_dict['Strides'] = layer.strides\n",
    "        if hasattr(layer, 'pool_size'):\n",
    "            layer_dict['Pooling Size'] = layer.pool_size\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_dict['Dropout Rate'] = layer.rate\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer_dict['Normalization Momentum'] = layer.momentum\n",
    "            layer_dict['Normalization Axis'] = layer.axis\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "            layer_dict['Reshape Target Shape'] = layer.target_shape\n",
    "        if layer.__class__.__name__ == 'Multiply':\n",
    "            layer_dict['Multiply'] = True\n",
    "        if layer.__class__.__name__ == 'Add':\n",
    "            layer_dict['Add'] = True\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# DataFrame list\n",
    "dfs = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    # Extract layer information\n",
    "    layer_info = extract_layer_info(model)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(layer_info)\n",
    "    # Append to the summary\n",
    "    dfs.append(df)\n",
    "\n",
    "    # Export DataFrame to a file (e.g., CSV)\n",
    "    df.to_csv(model.name + '_structure.csv', index=False)\n",
    "\n",
    "    # # Display DataFrame\n",
    "    # print(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Export concatenated DataFrame to a file (e.g., CSV)\n",
    "    result_df.to_csv('model_structure.csv', index=False)\n",
    "\n",
    "    # # Display concatenated DataFrame\n",
    "    # print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20322,
     "status": "ok",
     "timestamp": 1710842410615,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "BaloCYa4yoKn",
    "outputId": "028836da-70a0-417b-dbb9-eddec543a1c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71686520/71686520 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51877672/51877672 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n",
      "                     Model           Layer Name          Layer Type  built  \\\n",
      "0           efficientnetb4              input_1          InputLayer   True   \n",
      "1           efficientnetb4            rescaling           Rescaling   True   \n",
      "2           efficientnetb4        normalization       Normalization   True   \n",
      "3           efficientnetb4          rescaling_1           Rescaling   True   \n",
      "4           efficientnetb4        stem_conv_pad       ZeroPadding2D   True   \n",
      "...                    ...                  ...                 ...    ...   \n",
      "1413  mobilenetv2_1.00_224     block_16_project              Conv2D   True   \n",
      "1414  mobilenetv2_1.00_224  block_16_project_BN  BatchNormalization   True   \n",
      "1415  mobilenetv2_1.00_224               Conv_1              Conv2D   True   \n",
      "1416  mobilenetv2_1.00_224            Conv_1_bn  BatchNormalization   True   \n",
      "1417  mobilenetv2_1.00_224             out_relu                ReLU   True   \n",
      "\n",
      "     sparse ragged  batch_size is_placeholder  \\\n",
      "0     False  False         NaN           True   \n",
      "1       NaN    NaN         NaN            NaN   \n",
      "2       NaN    NaN         NaN            NaN   \n",
      "3       NaN    NaN         NaN            NaN   \n",
      "4       NaN    NaN         NaN            NaN   \n",
      "...     ...    ...         ...            ...   \n",
      "1413    NaN    NaN         NaN            NaN   \n",
      "1414    NaN    NaN         NaN            NaN   \n",
      "1415    NaN    NaN         NaN            NaN   \n",
      "1416    NaN    NaN         NaN            NaN   \n",
      "1417    NaN    NaN         NaN            NaN   \n",
      "\n",
      "                                                  scale  offset  ...  \\\n",
      "0                                                   NaN     NaN  ...   \n",
      "1                                              0.003922     0.0  ...   \n",
      "2                                                   NaN     NaN  ...   \n",
      "3     [2.0896918976428642, 2.1128856368212916, 2.108...     0.0  ...   \n",
      "4                                                   NaN     NaN  ...   \n",
      "...                                                 ...     ...  ...   \n",
      "1413                                                NaN     NaN  ...   \n",
      "1414                                               True     NaN  ...   \n",
      "1415                                                NaN     NaN  ...   \n",
      "1416                                               True     NaN  ...   \n",
      "1417                                                NaN     NaN  ...   \n",
      "\n",
      "     depthwise_kernel  keepdims  target_shape rate noise_shape seed pool_size  \\\n",
      "0                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "2                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "3                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "4                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "...               ...       ...           ...  ...         ...  ...       ...   \n",
      "1413              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1414              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1415              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1416              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1417              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "\n",
      "     max_value negative_slope threshold  \n",
      "0          NaN            NaN       NaN  \n",
      "1          NaN            NaN       NaN  \n",
      "2          NaN            NaN       NaN  \n",
      "3          NaN            NaN       NaN  \n",
      "4          NaN            NaN       NaN  \n",
      "...        ...            ...       ...  \n",
      "1413       NaN            NaN       NaN  \n",
      "1414       NaN            NaN       NaN  \n",
      "1415       NaN            NaN       NaN  \n",
      "1416       NaN            NaN       NaN  \n",
      "1417       6.0            0.0       0.0  \n",
      "\n",
      "[1418 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4, ResNet50, DenseNet169, VGG16, MobileNetV2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Models\n",
    "models = [EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380, 380, 3)),\n",
    "          ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "          DenseNet169(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "          VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "          MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))]\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'Model': model.name,\n",
    "            'Layer Name': layer.name,\n",
    "            'Layer Type': type(layer).__name__,\n",
    "        }\n",
    "        # Get all attributes of the layer\n",
    "        layer_attributes = layer.__dict__\n",
    "        for attr_name, attr_value in layer_attributes.items():\n",
    "            # Skip private attributes and methods\n",
    "            if not attr_name.startswith('_') and not callable(attr_value):\n",
    "                layer_dict[attr_name] = attr_value\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# DataFrame list\n",
    "dfs = []\n",
    "\n",
    "# Extract layer information for each model\n",
    "for model in models:\n",
    "    layer_info = extract_layer_info(model)\n",
    "    df = pd.DataFrame(layer_info)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Export concatenated DataFrame to a file (e.g., CSV)\n",
    "result_df.to_csv('combined_structure.csv', index=False)\n",
    "\n",
    "# Display concatenated DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# Load the ResNet50 model without the top classification layer\n",
    "model_backbones = [EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380,380,3)),\n",
    "         ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         DenseNet169(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)),]\n",
    "\n",
    "models = []\n",
    "\n",
    "for model in model_backbones:\n",
    "    backbone_name = model.name\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    pool = GlobalAveragePooling2D()(model.output)\n",
    "    dropout = Dropout(rate=0.4)(pool)\n",
    "    fc1 = Dense(1024, activation='relu')(dropout)\n",
    "    output = Dense(1, activation='sigmoid')(fc1)\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    model.name = backbone_name # Set the transfer-model name (format: functional_xx) to the backbone name\n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'model': model.name,\n",
    "            'layer_name': layer.name,\n",
    "            'layer_type': type(layer).__name__,\n",
    "            'input_shape': None, #str(layer.input) if isinstance(layer.input, list) else layer.input.shape if hasattr(layer, 'input') else None, # layer[0] = []\n",
    "            'output_shape': layer.output.shape, # {keras 2: layer.output_shape; keras 3: layer.output.shape}\n",
    "            'parameters': layer.count_params(),\n",
    "            'is_trainable': layer.trainable,\n",
    "            'layer_attributes': json.dumps(layer.get_config(), indent=2),\n",
    "            'activation_function': None,\n",
    "            'kernel_size': None,\n",
    "            'use_bias': None,\n",
    "            'padding': None,\n",
    "            'strides': None,\n",
    "            'pooling_size': None,\n",
    "            'dropout_rate': None,\n",
    "            'reshape_target_shape': None,\n",
    "\n",
    "        }\n",
    "\n",
    "        if isinstance(layer.input, list):\n",
    "            if len(layer.input) == 0: # layers[0] = []\n",
    "                layer_dict['input_shape'] = '[]'\n",
    "            else: # layers: Multiply, Add\n",
    "                input_shape = ''\n",
    "                for tensor in layer.input:\n",
    "                    input_shape += str(tensor.shape) + ', '\n",
    "                layer_dict['input_shape'] = input_shape[:-2] # Remove the last comma and space\n",
    "        elif hasattr(layer, 'input'):\n",
    "            layer_dict['input_shape'] = layer.input.shape\n",
    "\n",
    "        if hasattr(layer, 'activation'):\n",
    "            layer_dict['activation_function'] = layer.activation.__name__\n",
    "        if hasattr(layer, 'kernel_size'):\n",
    "            layer_dict['kernel_size'] = layer.kernel_size\n",
    "        if hasattr(layer, 'padding'):\n",
    "            layer_dict['padding'] = layer.padding\n",
    "        if hasattr(layer, 'strides'):\n",
    "            layer_dict['strides'] = layer.strides\n",
    "        if hasattr(layer, 'pool_size'):\n",
    "            layer_dict['pooling_size'] = layer.pool_size\n",
    "        if hasattr(layer, 'use_bias'):\n",
    "            layer_dict['use_bias'] = layer.use_bias\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_dict['dropout_rate'] = layer.rate\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "            layer_dict['reshape_target_shape'] = layer.target_shape\n",
    "\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# DataFrame list\n",
    "dfs = []\n",
    "model_structures = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    # Extract layer information\n",
    "    layer_info = extract_layer_info(model)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(layer_info)\n",
    "    # Append to the summary\n",
    "    dfs.append(df)\n",
    "\n",
    "    model_structures.append({\n",
    "        'model': model.name,\n",
    "        'structure': df\n",
    "    })\n",
    "\n",
    "    # Export DataFrame to a file (e.g., CSV)\n",
    "    df.to_csv(model.name + '_structure.csv', index=False)\n",
    "\n",
    "    # # Display DataFrame\n",
    "    # print(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Export concatenated DataFrame to a file (e.g., CSV)\n",
    "    result_df.to_csv('model_structure.csv', index=False)\n",
    "\n",
    "    # # Display concatenated DataFrame\n",
    "    # print(result_df)\n",
    "\n",
    "# Export to excel\n",
    "with pd.ExcelWriter('model_structure.xlsx') as writer:\n",
    "    for model in model_structures:\n",
    "        model['structure'].to_excel(writer, sheet_name=model['model'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_allow_non_tensor_positional_args',\n",
       " '_api_export_path',\n",
       " '_api_export_symbol_id',\n",
       " '_assert_input_compatibility',\n",
       " '_auto_config',\n",
       " '_batch_shape',\n",
       " '_build_by_run_for_kwargs',\n",
       " '_build_by_run_for_single_pos_arg',\n",
       " '_build_shapes_dict',\n",
       " '_call_has_mask_arg',\n",
       " '_call_has_training_arg',\n",
       " '_call_signature',\n",
       " '_called',\n",
       " '_check_quantize_args',\n",
       " '_check_super_called',\n",
       " '_checkpoint_adapter',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_convert_input_args',\n",
       " '_copy_trackable_to_cpu',\n",
       " '_default_save_signature',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_export_to_saved_model_graph',\n",
       " '_flatten_layers',\n",
       " '_float8_call',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_context',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_own_losses',\n",
       " '_get_regularization_losses',\n",
       " '_handle_deferred_dependencies',\n",
       " '_inbound_nodes',\n",
       " '_initialize_tracker',\n",
       " '_input_spec',\n",
       " '_input_tensor',\n",
       " '_int8_call',\n",
       " '_layers',\n",
       " '_lock',\n",
       " '_lock_state',\n",
       " '_lookup_dependency',\n",
       " '_loss_ids',\n",
       " '_losses',\n",
       " '_losses_override',\n",
       " '_maybe_build',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_reset_call_context',\n",
       " '_metrics',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_non_trainable_variables',\n",
       " '_not_implemented_error',\n",
       " '_obj_type',\n",
       " '_object_identifier',\n",
       " '_open_name_scope',\n",
       " '_outbound_nodes',\n",
       " '_parent_path',\n",
       " '_path',\n",
       " '_post_build',\n",
       " '_post_track_variable',\n",
       " '_post_untrack_variable',\n",
       " '_preload_simple_restoration',\n",
       " '_quantization_mode_error',\n",
       " '_restore_from_tensors',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_seed_generators',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_setattr_hook',\n",
       " '_setattr_tracking',\n",
       " '_supports_masking',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_track_variable',\n",
       " '_trackable_children',\n",
       " '_tracked',\n",
       " '_tracker',\n",
       " '_trainable',\n",
       " '_trainable_variables',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_unpickle_model',\n",
       " '_untrack_variable',\n",
       " '_update_uid',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'autocast',\n",
       " 'batch_shape',\n",
       " 'build',\n",
       " 'build_from_config',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compute_dtype',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_spec',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'from_config',\n",
       " 'get_build_config',\n",
       " 'get_config',\n",
       " 'get_weights',\n",
       " 'input',\n",
       " 'input_dtype',\n",
       " 'input_spec',\n",
       " 'load_own_variables',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_variables',\n",
       " 'name',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optional',\n",
       " 'output',\n",
       " 'path',\n",
       " 'quantization_mode',\n",
       " 'quantize',\n",
       " 'quantized_build',\n",
       " 'quantized_call',\n",
       " 'save_own_variables',\n",
       " 'set_weights',\n",
       " 'sparse',\n",
       " 'stateless_call',\n",
       " 'supports_jit',\n",
       " 'supports_masking',\n",
       " 'symbolic_call',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = model.layers[0]\n",
    "dir(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 224, 224, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 380, 380, 3), dtype=float32, sparse=False, name=keras_tensor>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Functional'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].name.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (trung bình): [[[[0.4999298  0.49999157 0.49986863]]]]\n",
      "Variance (phương sai): [[[[0.08332849 0.08332906 0.08333346]]]]\n",
      "Số tham số: 7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Normalization\n",
    "import numpy as np\n",
    "\n",
    "# Tạo một lớp Normalization\n",
    "norm_layer = Normalization(axis=-1)\n",
    "\n",
    "# Tạo dữ liệu giả để fit lớp Normalization\n",
    "data = np.random.rand(100, 380, 380, 3)\n",
    "\n",
    "# Fit lớp Normalization với dữ liệu\n",
    "norm_layer.adapt(data)\n",
    "\n",
    "# Kiểm tra trạng thái hiện tại\n",
    "print(\"Mean (trung bình):\", norm_layer.mean.numpy())\n",
    "print(\"Variance (phương sai):\", norm_layer.variance.numpy())\n",
    "print(\"Số tham số:\", norm_layer.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Flow của các khối trong ResNet-50**\n",
    "ResNet-50 có kiến trúc gồm **5 stages chính** (`conv1_x` đến `conv5_x`), trong đó mỗi stage bao gồm nhiều **Residual Blocks**. Dưới đây là sơ đồ tổng quan về dòng chảy dữ liệu (flow) trong ResNet-50.\n",
    "\n",
    "---\n",
    "\n",
    "### **1️⃣ Kiến trúc tổng thể của ResNet-50**\n",
    "| Stage   | Block | Layers (Conv2D) | Output Shape |\n",
    "|---------|-------|-----------------|--------------|\n",
    "| **conv1** | - | 7×7 Conv, MaxPool | (112, 112, 64) |\n",
    "| **conv2_x** | Block 1 | 1×1, 3×3, 1×1 (+ projection) | (56, 56, 256) |\n",
    "|           | Block 2 | 1×1, 3×3, 1×1 | (56, 56, 256) |\n",
    "|           | Block 3 | 1×1, 3×3, 1×1 | (56, 56, 256) |\n",
    "| **conv3_x** | Block 1 | 1×1, 3×3, 1×1 (+ projection, stride=2) | (28, 28, 512) |\n",
    "|           | Block 2 | 1×1, 3×3, 1×1 | (28, 28, 512) |\n",
    "|           | Block 3 | 1×1, 3×3, 1×1 | (28, 28, 512) |\n",
    "|           | Block 4 | 1×1, 3×3, 1×1 | (28, 28, 512) |\n",
    "| **conv4_x** | Block 1 | 1×1, 3×3, 1×1 (+ projection, stride=2) | (14, 14, 1024) |\n",
    "|           | Block 2 | 1×1, 3×3, 1×1 | (14, 14, 1024) |\n",
    "|           | ... | ... | ... |\n",
    "|           | Block 6 | 1×1, 3×3, 1×1 | (14, 14, 1024) |\n",
    "| **conv5_x** | Block 1 | 1×1, 3×3, 1×1 (+ projection, stride=2) | (7, 7, 2048) |\n",
    "|           | Block 2 | 1×1, 3×3, 1×1 | (7, 7, 2048) |\n",
    "|           | Block 3 | 1×1, 3×3, 1×1 | (7, 7, 2048) |\n",
    "| **Output** | - | Global Average Pooling, Dense | (1000,) |\n",
    "\n",
    "🔹 **Các điểm quan trọng:**\n",
    "- **Block đầu tiên của mỗi stage có projection layer (1×1 Conv)** để tăng số channels và giảm kích thước không gian (`stride=2`).\n",
    "- **Các block còn lại có skip connection chuẩn (x + F(x))**.\n",
    "- **conv1 chỉ có một Conv2D duy nhất (7×7, stride=2)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Flow chi tiết của một Residual Block**\n",
    "Mỗi block trong ResNet-50 có cấu trúc như sau:\n",
    "\n",
    "```\n",
    "Input → 1×1 Conv (Reduce) → 3×3 Conv (Feature Extraction) → 1×1 Conv (Expand)\n",
    "      → (Projection nếu cần) → Add (Skip Connection) → ReLU\n",
    "```\n",
    "\n",
    "Dưới đây là sơ đồ minh họa **flow của một Residual Block** trong `conv3_x`:\n",
    "\n",
    "```\n",
    "       Input (28×28×256)\n",
    "            │\n",
    "   ┌────────┴────────┐\n",
    "   │ 1×1 Conv (128)  │    # Giảm số channels\n",
    "   │ BN + ReLU       │\n",
    "   └─────────────────┘\n",
    "            │\n",
    "   ┌────────┴────────┐\n",
    "   │ 3×3 Conv (128)  │    # Học đặc trưng\n",
    "   │ BN + ReLU       │\n",
    "   └─────────────────┘\n",
    "            │\n",
    "   ┌────────┴────────┐\n",
    "   │ 1×1 Conv (512)  │    # Tăng số channels\n",
    "   │ BN              │\n",
    "   └─────────────────┘\n",
    "            │\n",
    "   ┌────────┴────────┐\n",
    "   │ Projection (1×1) │    # Nếu là block đầu tiên\n",
    "   │ BN              │\n",
    "   └─────────────────┘\n",
    "            │\n",
    "       Skip Connection\n",
    "            │\n",
    "          ReLU\n",
    "            │\n",
    "      Output (28×28×512)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Biểu diễn bằng Keras Code**\n",
    "Dưới đây là cách viết một **Residual Block** trong Keras:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Add, Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def resnet_block(x, filters, stride=1, projection=False):\n",
    "    shortcut = x  # Giữ lại đầu vào ban đầu\n",
    "\n",
    "    # 1x1 Conv (Reduce)\n",
    "    x = Conv2D(filters//4, kernel_size=1, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # 3x3 Conv (Feature Extraction)\n",
    "    x = Conv2D(filters//4, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # 1x1 Conv (Expand)\n",
    "    x = Conv2D(filters, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Projection nếu cần (dùng khi stride=2 hoặc số channels thay đổi)\n",
    "    if projection:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=stride, padding='same', use_bias=False)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # Skip Connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Kiểm tra mô hình với đầu vào 28x28x256\n",
    "input_layer = Input(shape=(28, 28, 256))\n",
    "output_layer = resnet_block(input_layer, filters=512, stride=1, projection=True)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Tổng kết**\n",
    "✅ **ResNet-50 chia thành 5 stages (`conv1_x` → `conv5_x`).**  \n",
    "✅ **Mỗi stage có nhiều Residual Blocks, mỗi block có 3 Conv2D layers.**  \n",
    "✅ **Block đầu tiên của mỗi stage có Projection Layer (1×1 Conv) để thay đổi số channels.**  \n",
    "✅ **Dữ liệu truyền qua từng block theo thứ tự: 1×1 Conv → 3×3 Conv → 1×1 Conv → Skip Connection → ReLU.**  \n",
    "✅ **Skip Connection giúp tránh vanishing gradient, giúp mô hình học tốt hơn.**  \n",
    "\n",
    "Bạn cần biểu diễn flow bằng sơ đồ đồ họa không, hay cách viết này là đủ? 🚀"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUXhxPDpH0uDx5kwHFzhYo",
   "mount_file_id": "1hm4RS5Y6MOsK4ZwqJb6PE16P5tmty2p8",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
