{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure v1 (deprecate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11916,
     "status": "ok",
     "timestamp": 1711032044091,
     "user": {
      "displayName": "Quang H√πng Tr·∫ßn (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "a_MZCpkCjFS9",
    "outputId": "98feb81a-3835-41b1-fc0e-0711292bb2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1711032045003,
     "user": {
      "displayName": "Quang H√πng Tr·∫ßn (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "NN_BYkTvj7QA",
    "outputId": "9793a006-ebed-437d-f5ab-38c4fc48f02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/Thesis/Model\n"
     ]
    }
   ],
   "source": [
    "cd '/content/drive/MyDrive/Colab Notebooks/Thesis/Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7059,
     "status": "ok",
     "timestamp": 1710811707843,
     "user": {
      "displayName": "Quang H√πng Tr·∫ßn (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "nmDGbx1zicXK",
    "outputId": "63b77019-b961-45ba-8f03-8afa82bbe3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name                Type           Output Shape  Trainable  \\\n",
      "0            input_9          InputLayer  [(None, 224, 224, 3)]       True   \n",
      "1        rescaling_4           Rescaling    (None, 224, 224, 3)       True   \n",
      "2    normalization_2       Normalization    (None, 224, 224, 3)       True   \n",
      "3        rescaling_5           Rescaling    (None, 224, 224, 3)       True   \n",
      "4      stem_conv_pad       ZeroPadding2D    (None, 225, 225, 3)       True   \n",
      "..               ...                 ...                    ...        ...   \n",
      "470     block7b_drop             Dropout      (None, 7, 7, 448)       True   \n",
      "471      block7b_add                 Add      (None, 7, 7, 448)       True   \n",
      "472         top_conv              Conv2D     (None, 7, 7, 1792)       True   \n",
      "473           top_bn  BatchNormalization     (None, 7, 7, 1792)       True   \n",
      "474   top_activation          Activation     (None, 7, 7, 1792)       True   \n",
      "\n",
      "     Number of Parameters Activation Function Kernel Size           Padding  \\\n",
      "0                       0                None        None              None   \n",
      "1                       0                None        None              None   \n",
      "2                       7                None        None              None   \n",
      "3                       0                None        None              None   \n",
      "4                       0                None        None  ((0, 1), (0, 1))   \n",
      "..                    ...                 ...         ...               ...   \n",
      "470                     0                None        None              None   \n",
      "471                     0                None        None              None   \n",
      "472                802816              linear      (1, 1)              same   \n",
      "473                  7168                None        None              None   \n",
      "474                     0               swish        None              None   \n",
      "\n",
      "    Strides Pooling Size  Dropout Rate  Normalization Momentum  \\\n",
      "0      None         None           NaN                     NaN   \n",
      "1      None         None           NaN                     NaN   \n",
      "2      None         None           NaN                     NaN   \n",
      "3      None         None           NaN                     NaN   \n",
      "4      None         None           NaN                     NaN   \n",
      "..      ...          ...           ...                     ...   \n",
      "470    None         None       0.19375                     NaN   \n",
      "471    None         None           NaN                     NaN   \n",
      "472  (1, 1)         None           NaN                     NaN   \n",
      "473    None         None           NaN                    0.99   \n",
      "474    None         None           NaN                     NaN   \n",
      "\n",
      "    Normalization Axis Reshape Target Shape  \n",
      "0                 None                 None  \n",
      "1                 None                 None  \n",
      "2                 None                 None  \n",
      "3                 None                 None  \n",
      "4                 None                 None  \n",
      "..                 ...                  ...  \n",
      "470               None                 None  \n",
      "471               None                 None  \n",
      "472               None                 None  \n",
      "473                [3]                 None  \n",
      "474               None                 None  \n",
      "\n",
      "[475 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the ResNet50 model without the top classification layer\n",
    "model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'Model': model.name,\n",
    "            'Layer Name': layer.name,\n",
    "            'Layer Type': type(layer).__name__,\n",
    "            'Output Shape': layer.output_shape,\n",
    "            'Trainable': layer.trainable,\n",
    "            'Number of Parameters': layer.count_params(),\n",
    "            'Activation Function': None,\n",
    "            'Kernel Size': None,\n",
    "            'Padding': None,\n",
    "            'Strides': None,\n",
    "            'Pooling Size': None,\n",
    "            'Dropout Rate': None,\n",
    "            'Normalization Momentum': None,\n",
    "            'Normalization Axis': None,\n",
    "            'Reshape Target Shape': None,\n",
    "            'Multiply': False,\n",
    "            'Add': False,\n",
    "\n",
    "        }\n",
    "\n",
    "        if hasattr(layer, 'activation'):\n",
    "            layer_dict['Activation Function'] = layer.activation.__name__\n",
    "        if hasattr(layer, 'kernel_size'):\n",
    "            layer_dict['Kernel Size'] = layer.kernel_size\n",
    "        if hasattr(layer, 'padding'):\n",
    "            layer_dict['Padding'] = layer.padding\n",
    "        if hasattr(layer, 'strides'):\n",
    "            layer_dict['Strides'] = layer.strides\n",
    "        if hasattr(layer, 'pool_size'):\n",
    "            layer_dict['Pooling Size'] = layer.pool_size\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_dict['Dropout Rate'] = layer.rate\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer_dict['Normalization Momentum'] = layer.momentum\n",
    "            layer_dict['Normalization Axis'] = layer.axis\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "            layer_dict['Reshape Target Shape'] = layer.target_shape\n",
    "        if layer.__class__.__name__ == 'Multiply':\n",
    "            layer_dict['Multiply'] = True\n",
    "        if layer.__class__.__name__ == 'Add':\n",
    "            layer_dict['Add'] = True\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# Extract layer information\n",
    "layer_info = extract_layer_info(model)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(layer_info)\n",
    "\n",
    "# Export DataFrame to a file (e.g., CSV)\n",
    "df.to_csv('efficientnetb4_structure.csv', index=False)\n",
    "\n",
    "# Display DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 17888,
     "status": "ok",
     "timestamp": 1711032454481,
     "user": {
      "displayName": "Quang H√πng Tr·∫ßn (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "fPSal9s9kSS-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the ResNet50 model without the top classification layer\n",
    "models = [EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380,380,3)),\n",
    "         ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         DenseNet169(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)),]\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    \n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'Model': model.name,\n",
    "            'Layer Name': layer.name,\n",
    "            'Layer Type': type(layer).__name__,\n",
    "            'Output Shape': layer.output_shape,\n",
    "            'Trainable': layer.trainable,\n",
    "            'Number of Parameters': layer.count_params(),\n",
    "            'Activation Function': None,\n",
    "            'Kernel Size': None,\n",
    "            'Padding': None,\n",
    "            'Strides': None,\n",
    "            'Pooling Size': None,\n",
    "            'Dropout Rate': None,\n",
    "            'Normalization Momentum': None,\n",
    "            'Normalization Axis': None,\n",
    "            'Reshape Target Shape': None,\n",
    "            'Multiply': False,\n",
    "            'Add': False,\n",
    "\n",
    "        }\n",
    "\n",
    "        if hasattr(layer, 'activation'):\n",
    "            layer_dict['Activation Function'] = layer.activation.__name__\n",
    "        if hasattr(layer, 'kernel_size'):\n",
    "            layer_dict['Kernel Size'] = layer.kernel_size\n",
    "        if hasattr(layer, 'padding'):\n",
    "            layer_dict['Padding'] = layer.padding\n",
    "        if hasattr(layer, 'strides'):\n",
    "            layer_dict['Strides'] = layer.strides\n",
    "        if hasattr(layer, 'pool_size'):\n",
    "            layer_dict['Pooling Size'] = layer.pool_size\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_dict['Dropout Rate'] = layer.rate\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer_dict['Normalization Momentum'] = layer.momentum\n",
    "            layer_dict['Normalization Axis'] = layer.axis\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "            layer_dict['Reshape Target Shape'] = layer.target_shape\n",
    "        if layer.__class__.__name__ == 'Multiply':\n",
    "            layer_dict['Multiply'] = True\n",
    "        if layer.__class__.__name__ == 'Add':\n",
    "            layer_dict['Add'] = True\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# DataFrame list\n",
    "dfs = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    # Extract layer information\n",
    "    layer_info = extract_layer_info(model)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(layer_info)\n",
    "    # Append to the summary\n",
    "    dfs.append(df)\n",
    "\n",
    "    # Export DataFrame to a file (e.g., CSV)\n",
    "    df.to_csv(model.name + '_structure.csv', index=False)\n",
    "\n",
    "    # # Display DataFrame\n",
    "    # print(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Export concatenated DataFrame to a file (e.g., CSV)\n",
    "    result_df.to_csv('model_structure.csv', index=False)\n",
    "\n",
    "    # # Display concatenated DataFrame\n",
    "    # print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20322,
     "status": "ok",
     "timestamp": 1710842410615,
     "user": {
      "displayName": "Quang H√πng Tr·∫ßn (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "BaloCYa4yoKn",
    "outputId": "028836da-70a0-417b-dbb9-eddec543a1c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71686520/71686520 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51877672/51877672 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n",
      "                     Model           Layer Name          Layer Type  built  \\\n",
      "0           efficientnetb4              input_1          InputLayer   True   \n",
      "1           efficientnetb4            rescaling           Rescaling   True   \n",
      "2           efficientnetb4        normalization       Normalization   True   \n",
      "3           efficientnetb4          rescaling_1           Rescaling   True   \n",
      "4           efficientnetb4        stem_conv_pad       ZeroPadding2D   True   \n",
      "...                    ...                  ...                 ...    ...   \n",
      "1413  mobilenetv2_1.00_224     block_16_project              Conv2D   True   \n",
      "1414  mobilenetv2_1.00_224  block_16_project_BN  BatchNormalization   True   \n",
      "1415  mobilenetv2_1.00_224               Conv_1              Conv2D   True   \n",
      "1416  mobilenetv2_1.00_224            Conv_1_bn  BatchNormalization   True   \n",
      "1417  mobilenetv2_1.00_224             out_relu                ReLU   True   \n",
      "\n",
      "     sparse ragged  batch_size is_placeholder  \\\n",
      "0     False  False         NaN           True   \n",
      "1       NaN    NaN         NaN            NaN   \n",
      "2       NaN    NaN         NaN            NaN   \n",
      "3       NaN    NaN         NaN            NaN   \n",
      "4       NaN    NaN         NaN            NaN   \n",
      "...     ...    ...         ...            ...   \n",
      "1413    NaN    NaN         NaN            NaN   \n",
      "1414    NaN    NaN         NaN            NaN   \n",
      "1415    NaN    NaN         NaN            NaN   \n",
      "1416    NaN    NaN         NaN            NaN   \n",
      "1417    NaN    NaN         NaN            NaN   \n",
      "\n",
      "                                                  scale  offset  ...  \\\n",
      "0                                                   NaN     NaN  ...   \n",
      "1                                              0.003922     0.0  ...   \n",
      "2                                                   NaN     NaN  ...   \n",
      "3     [2.0896918976428642, 2.1128856368212916, 2.108...     0.0  ...   \n",
      "4                                                   NaN     NaN  ...   \n",
      "...                                                 ...     ...  ...   \n",
      "1413                                                NaN     NaN  ...   \n",
      "1414                                               True     NaN  ...   \n",
      "1415                                                NaN     NaN  ...   \n",
      "1416                                               True     NaN  ...   \n",
      "1417                                                NaN     NaN  ...   \n",
      "\n",
      "     depthwise_kernel  keepdims  target_shape rate noise_shape seed pool_size  \\\n",
      "0                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "2                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "3                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "4                 NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "...               ...       ...           ...  ...         ...  ...       ...   \n",
      "1413              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1414              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1415              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1416              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "1417              NaN       NaN           NaN  NaN         NaN  NaN       NaN   \n",
      "\n",
      "     max_value negative_slope threshold  \n",
      "0          NaN            NaN       NaN  \n",
      "1          NaN            NaN       NaN  \n",
      "2          NaN            NaN       NaN  \n",
      "3          NaN            NaN       NaN  \n",
      "4          NaN            NaN       NaN  \n",
      "...        ...            ...       ...  \n",
      "1413       NaN            NaN       NaN  \n",
      "1414       NaN            NaN       NaN  \n",
      "1415       NaN            NaN       NaN  \n",
      "1416       NaN            NaN       NaN  \n",
      "1417       6.0            0.0       0.0  \n",
      "\n",
      "[1418 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4, ResNet50, DenseNet169, VGG16, MobileNetV2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Models\n",
    "models = [EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380, 380, 3)),\n",
    "          ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "          DenseNet169(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "          VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "          MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))]\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'Model': model.name,\n",
    "            'Layer Name': layer.name,\n",
    "            'Layer Type': type(layer).__name__,\n",
    "        }\n",
    "        # Get all attributes of the layer\n",
    "        layer_attributes = layer.__dict__\n",
    "        for attr_name, attr_value in layer_attributes.items():\n",
    "            # Skip private attributes and methods\n",
    "            if not attr_name.startswith('_') and not callable(attr_value):\n",
    "                layer_dict[attr_name] = attr_value\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# DataFrame list\n",
    "dfs = []\n",
    "\n",
    "# Extract layer information for each model\n",
    "for model in models:\n",
    "    layer_info = extract_layer_info(model)\n",
    "    df = pd.DataFrame(layer_info)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Export concatenated DataFrame to a file (e.g., CSV)\n",
    "result_df.to_csv('combined_structure.csv', index=False)\n",
    "\n",
    "# Display concatenated DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# Load the ResNet50 model without the top classification layer\n",
    "model_backbones = [EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380,380,3)),\n",
    "         ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         DenseNet169(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)),\n",
    "         MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)),]\n",
    "\n",
    "models = []\n",
    "\n",
    "for model in model_backbones:\n",
    "    backbone_name = model.name\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    pool = GlobalAveragePooling2D()(model.output)\n",
    "    dropout = Dropout(rate=0.4)(pool)\n",
    "    fc1 = Dense(1024, activation='relu')(dropout)\n",
    "    output = Dense(1, activation='sigmoid')(fc1)\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    model.name = backbone_name # Set the transfer-model name (format: functional_xx) to the backbone name\n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "# Function to extract layer information\n",
    "def extract_layer_info(model):\n",
    "    layer_info = []\n",
    "    for layer in model.layers:\n",
    "        layer_dict = {\n",
    "            'model': model.name,\n",
    "            'layer_name': layer.name,\n",
    "            'layer_type': type(layer).__name__,\n",
    "            'input_shape': None, #str(layer.input) if isinstance(layer.input, list) else layer.input.shape if hasattr(layer, 'input') else None, # layer[0] = []\n",
    "            'output_shape': layer.output.shape, # {keras 2: layer.output_shape; keras 3: layer.output.shape}\n",
    "            'parameters': layer.count_params(),\n",
    "            'is_trainable': layer.trainable,\n",
    "            'layer_attributes': json.dumps(layer.get_config(), indent=2),\n",
    "            'activation_function': None,\n",
    "            'kernel_size': None,\n",
    "            'use_bias': None,\n",
    "            'padding': None,\n",
    "            'strides': None,\n",
    "            'pooling_size': None,\n",
    "            'dropout_rate': None,\n",
    "            'reshape_target_shape': None,\n",
    "\n",
    "        }\n",
    "\n",
    "        if isinstance(layer.input, list):\n",
    "            if len(layer.input) == 0: # layers[0] = []\n",
    "                layer_dict['input_shape'] = '[]'\n",
    "            else: # layers: Multiply, Add\n",
    "                input_shape = ''\n",
    "                for tensor in layer.input:\n",
    "                    input_shape += str(tensor.shape) + ', '\n",
    "                layer_dict['input_shape'] = input_shape[:-2] # Remove the last comma and space\n",
    "        elif hasattr(layer, 'input'):\n",
    "            layer_dict['input_shape'] = layer.input.shape\n",
    "\n",
    "        if hasattr(layer, 'activation'):\n",
    "            layer_dict['activation_function'] = layer.activation.__name__\n",
    "        if hasattr(layer, 'kernel_size'):\n",
    "            layer_dict['kernel_size'] = layer.kernel_size\n",
    "        if hasattr(layer, 'padding'):\n",
    "            layer_dict['padding'] = layer.padding\n",
    "        if hasattr(layer, 'strides'):\n",
    "            layer_dict['strides'] = layer.strides\n",
    "        if hasattr(layer, 'pool_size'):\n",
    "            layer_dict['pooling_size'] = layer.pool_size\n",
    "        if hasattr(layer, 'use_bias'):\n",
    "            layer_dict['use_bias'] = layer.use_bias\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer_dict['dropout_rate'] = layer.rate\n",
    "        if isinstance(layer, tf.keras.layers.Reshape):\n",
    "            layer_dict['reshape_target_shape'] = layer.target_shape\n",
    "\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "    return layer_info\n",
    "\n",
    "# DataFrame list\n",
    "dfs = []\n",
    "model_structures = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    # Extract layer information\n",
    "    layer_info = extract_layer_info(model)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(layer_info)\n",
    "    # Append to the summary\n",
    "    dfs.append(df)\n",
    "\n",
    "    model_structures.append({\n",
    "        'model': model.name,\n",
    "        'structure': df\n",
    "    })\n",
    "\n",
    "    # Export DataFrame to a file (e.g., CSV)\n",
    "    df.to_csv(model.name + '_structure.csv', index=False)\n",
    "\n",
    "    # # Display DataFrame\n",
    "    # print(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Export concatenated DataFrame to a file (e.g., CSV)\n",
    "    result_df.to_csv('model_structure.csv', index=False)\n",
    "\n",
    "    # # Display concatenated DataFrame\n",
    "    # print(result_df)\n",
    "\n",
    "# Export to excel\n",
    "with pd.ExcelWriter('model_structure.xlsx') as writer:\n",
    "    for model in model_structures:\n",
    "        model['structure'].to_excel(writer, sheet_name=model['model'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_allow_non_tensor_positional_args',\n",
       " '_api_export_path',\n",
       " '_api_export_symbol_id',\n",
       " '_assert_input_compatibility',\n",
       " '_auto_config',\n",
       " '_batch_shape',\n",
       " '_build_by_run_for_kwargs',\n",
       " '_build_by_run_for_single_pos_arg',\n",
       " '_build_shapes_dict',\n",
       " '_call_has_mask_arg',\n",
       " '_call_has_training_arg',\n",
       " '_call_signature',\n",
       " '_called',\n",
       " '_check_quantize_args',\n",
       " '_check_super_called',\n",
       " '_checkpoint_adapter',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_convert_input_args',\n",
       " '_copy_trackable_to_cpu',\n",
       " '_default_save_signature',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_export_to_saved_model_graph',\n",
       " '_flatten_layers',\n",
       " '_float8_call',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_context',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_own_losses',\n",
       " '_get_regularization_losses',\n",
       " '_handle_deferred_dependencies',\n",
       " '_inbound_nodes',\n",
       " '_initialize_tracker',\n",
       " '_input_spec',\n",
       " '_input_tensor',\n",
       " '_int8_call',\n",
       " '_layers',\n",
       " '_lock',\n",
       " '_lock_state',\n",
       " '_lookup_dependency',\n",
       " '_loss_ids',\n",
       " '_losses',\n",
       " '_losses_override',\n",
       " '_maybe_build',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_reset_call_context',\n",
       " '_metrics',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_non_trainable_variables',\n",
       " '_not_implemented_error',\n",
       " '_obj_type',\n",
       " '_object_identifier',\n",
       " '_open_name_scope',\n",
       " '_outbound_nodes',\n",
       " '_parent_path',\n",
       " '_path',\n",
       " '_post_build',\n",
       " '_post_track_variable',\n",
       " '_post_untrack_variable',\n",
       " '_preload_simple_restoration',\n",
       " '_quantization_mode_error',\n",
       " '_restore_from_tensors',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_seed_generators',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_setattr_hook',\n",
       " '_setattr_tracking',\n",
       " '_supports_masking',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_track_variable',\n",
       " '_trackable_children',\n",
       " '_tracked',\n",
       " '_tracker',\n",
       " '_trainable',\n",
       " '_trainable_variables',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_unpickle_model',\n",
       " '_untrack_variable',\n",
       " '_update_uid',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'autocast',\n",
       " 'batch_shape',\n",
       " 'build',\n",
       " 'build_from_config',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compute_dtype',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_spec',\n",
       " 'count_params',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'from_config',\n",
       " 'get_build_config',\n",
       " 'get_config',\n",
       " 'get_weights',\n",
       " 'input',\n",
       " 'input_dtype',\n",
       " 'input_spec',\n",
       " 'load_own_variables',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_variables',\n",
       " 'name',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optional',\n",
       " 'output',\n",
       " 'path',\n",
       " 'quantization_mode',\n",
       " 'quantize',\n",
       " 'quantized_build',\n",
       " 'quantized_call',\n",
       " 'save_own_variables',\n",
       " 'set_weights',\n",
       " 'sparse',\n",
       " 'stateless_call',\n",
       " 'supports_jit',\n",
       " 'supports_masking',\n",
       " 'symbolic_call',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = model.layers[0]\n",
    "dir(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 224, 224, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 380, 380, 3), dtype=float32, sparse=False, name=keras_tensor>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Functional'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].name.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (trung b√¨nh): [[[[0.4999298  0.49999157 0.49986863]]]]\n",
      "Variance (ph∆∞∆°ng sai): [[[[0.08332849 0.08332906 0.08333346]]]]\n",
      "S·ªë tham s·ªë: 7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Normalization\n",
    "import numpy as np\n",
    "\n",
    "# T·∫°o m·ªôt l·ªõp Normalization\n",
    "norm_layer = Normalization(axis=-1)\n",
    "\n",
    "# T·∫°o d·ªØ li·ªáu gi·∫£ ƒë·ªÉ fit l·ªõp Normalization\n",
    "data = np.random.rand(100, 380, 380, 3)\n",
    "\n",
    "# Fit l·ªõp Normalization v·ªõi d·ªØ li·ªáu\n",
    "norm_layer.adapt(data)\n",
    "\n",
    "# Ki·ªÉm tra tr·∫°ng th√°i hi·ªán t·∫°i\n",
    "print(\"Mean (trung b√¨nh):\", norm_layer.mean.numpy())\n",
    "print(\"Variance (ph∆∞∆°ng sai):\", norm_layer.variance.numpy())\n",
    "print(\"S·ªë tham s·ªë:\", norm_layer.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Flow c·ªßa c√°c kh·ªëi trong ResNet-50**\n",
    "ResNet-50 c√≥ ki·∫øn tr√∫c g·ªìm **5 stages ch√≠nh** (`conv1_x` ƒë·∫øn `conv5_x`), trong ƒë√≥ m·ªói stage bao g·ªìm nhi·ªÅu **Residual Blocks**. D∆∞·ªõi ƒë√¢y l√† s∆° ƒë·ªì t·ªïng quan v·ªÅ d√≤ng ch·∫£y d·ªØ li·ªáu (flow) trong ResNet-50.\n",
    "\n",
    "---\n",
    "\n",
    "### **1Ô∏è‚É£ Ki·∫øn tr√∫c t·ªïng th·ªÉ c·ªßa ResNet-50**\n",
    "| Stage   | Block | Layers (Conv2D) | Output Shape |\n",
    "|---------|-------|-----------------|--------------|\n",
    "| **conv1** | - | 7√ó7 Conv, MaxPool | (112, 112, 64) |\n",
    "| **conv2_x** | Block 1 | 1√ó1, 3√ó3, 1√ó1 (+ projection) | (56, 56, 256) |\n",
    "|           | Block 2 | 1√ó1, 3√ó3, 1√ó1 | (56, 56, 256) |\n",
    "|           | Block 3 | 1√ó1, 3√ó3, 1√ó1 | (56, 56, 256) |\n",
    "| **conv3_x** | Block 1 | 1√ó1, 3√ó3, 1√ó1 (+ projection, stride=2) | (28, 28, 512) |\n",
    "|           | Block 2 | 1√ó1, 3√ó3, 1√ó1 | (28, 28, 512) |\n",
    "|           | Block 3 | 1√ó1, 3√ó3, 1√ó1 | (28, 28, 512) |\n",
    "|           | Block 4 | 1√ó1, 3√ó3, 1√ó1 | (28, 28, 512) |\n",
    "| **conv4_x** | Block 1 | 1√ó1, 3√ó3, 1√ó1 (+ projection, stride=2) | (14, 14, 1024) |\n",
    "|           | Block 2 | 1√ó1, 3√ó3, 1√ó1 | (14, 14, 1024) |\n",
    "|           | ... | ... | ... |\n",
    "|           | Block 6 | 1√ó1, 3√ó3, 1√ó1 | (14, 14, 1024) |\n",
    "| **conv5_x** | Block 1 | 1√ó1, 3√ó3, 1√ó1 (+ projection, stride=2) | (7, 7, 2048) |\n",
    "|           | Block 2 | 1√ó1, 3√ó3, 1√ó1 | (7, 7, 2048) |\n",
    "|           | Block 3 | 1√ó1, 3√ó3, 1√ó1 | (7, 7, 2048) |\n",
    "| **Output** | - | Global Average Pooling, Dense | (1000,) |\n",
    "\n",
    "üîπ **C√°c ƒëi·ªÉm quan tr·ªçng:**\n",
    "- **Block ƒë·∫ßu ti√™n c·ªßa m·ªói stage c√≥ projection layer (1√ó1 Conv)** ƒë·ªÉ tƒÉng s·ªë channels v√† gi·∫£m k√≠ch th∆∞·ªõc kh√¥ng gian (`stride=2`).\n",
    "- **C√°c block c√≤n l·∫°i c√≥ skip connection chu·∫©n (x + F(x))**.\n",
    "- **conv1 ch·ªâ c√≥ m·ªôt Conv2D duy nh·∫•t (7√ó7, stride=2)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Flow chi ti·∫øt c·ªßa m·ªôt Residual Block**\n",
    "M·ªói block trong ResNet-50 c√≥ c·∫•u tr√∫c nh∆∞ sau:\n",
    "\n",
    "```\n",
    "Input ‚Üí 1√ó1 Conv (Reduce) ‚Üí 3√ó3 Conv (Feature Extraction) ‚Üí 1√ó1 Conv (Expand)\n",
    "      ‚Üí (Projection n·∫øu c·∫ßn) ‚Üí Add (Skip Connection) ‚Üí ReLU\n",
    "```\n",
    "\n",
    "D∆∞·ªõi ƒë√¢y l√† s∆° ƒë·ªì minh h·ªça **flow c·ªßa m·ªôt Residual Block** trong `conv3_x`:\n",
    "\n",
    "```\n",
    "       Input (28√ó28√ó256)\n",
    "            ‚îÇ\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ 1√ó1 Conv (128)  ‚îÇ    # Gi·∫£m s·ªë channels\n",
    "   ‚îÇ BN + ReLU       ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ 3√ó3 Conv (128)  ‚îÇ    # H·ªçc ƒë·∫∑c tr∆∞ng\n",
    "   ‚îÇ BN + ReLU       ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ 1√ó1 Conv (512)  ‚îÇ    # TƒÉng s·ªë channels\n",
    "   ‚îÇ BN              ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ Projection (1√ó1) ‚îÇ    # N·∫øu l√† block ƒë·∫ßu ti√™n\n",
    "   ‚îÇ BN              ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "       Skip Connection\n",
    "            ‚îÇ\n",
    "          ReLU\n",
    "            ‚îÇ\n",
    "      Output (28√ó28√ó512)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3Ô∏è‚É£ Bi·ªÉu di·ªÖn b·∫±ng Keras Code**\n",
    "D∆∞·ªõi ƒë√¢y l√† c√°ch vi·∫øt m·ªôt **Residual Block** trong Keras:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Add, Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def resnet_block(x, filters, stride=1, projection=False):\n",
    "    shortcut = x  # Gi·ªØ l·∫°i ƒë·∫ßu v√†o ban ƒë·∫ßu\n",
    "\n",
    "    # 1x1 Conv (Reduce)\n",
    "    x = Conv2D(filters//4, kernel_size=1, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # 3x3 Conv (Feature Extraction)\n",
    "    x = Conv2D(filters//4, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # 1x1 Conv (Expand)\n",
    "    x = Conv2D(filters, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Projection n·∫øu c·∫ßn (d√πng khi stride=2 ho·∫∑c s·ªë channels thay ƒë·ªïi)\n",
    "    if projection:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=stride, padding='same', use_bias=False)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # Skip Connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Ki·ªÉm tra m√¥ h√¨nh v·ªõi ƒë·∫ßu v√†o 28x28x256\n",
    "input_layer = Input(shape=(28, 28, 256))\n",
    "output_layer = resnet_block(input_layer, filters=512, stride=1, projection=True)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4Ô∏è‚É£ T·ªïng k·∫øt**\n",
    "‚úÖ **ResNet-50 chia th√†nh 5 stages (`conv1_x` ‚Üí `conv5_x`).**  \n",
    "‚úÖ **M·ªói stage c√≥ nhi·ªÅu Residual Blocks, m·ªói block c√≥ 3 Conv2D layers.**  \n",
    "‚úÖ **Block ƒë·∫ßu ti√™n c·ªßa m·ªói stage c√≥ Projection Layer (1√ó1 Conv) ƒë·ªÉ thay ƒë·ªïi s·ªë channels.**  \n",
    "‚úÖ **D·ªØ li·ªáu truy·ªÅn qua t·ª´ng block theo th·ª© t·ª±: 1√ó1 Conv ‚Üí 3√ó3 Conv ‚Üí 1√ó1 Conv ‚Üí Skip Connection ‚Üí ReLU.**  \n",
    "‚úÖ **Skip Connection gi√∫p tr√°nh vanishing gradient, gi√∫p m√¥ h√¨nh h·ªçc t·ªët h∆°n.**  \n",
    "\n",
    "B·∫°n c·∫ßn bi·ªÉu di·ªÖn flow b·∫±ng s∆° ƒë·ªì ƒë·ªì h·ªça kh√¥ng, hay c√°ch vi·∫øt n√†y l√† ƒë·ªß? üöÄ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUXhxPDpH0uDx5kwHFzhYo",
   "mount_file_id": "1hm4RS5Y6MOsK4ZwqJb6PE16P5tmty2p8",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
